{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Opcional per evitar warnings de HTTPS\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracción de empresas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for year in [2025, 2024, 2023, 2022]:\n",
    "    for pa in range(1, 8):\n",
    "        url = f\"https://startupshub.catalonia.com/investments-in-catalan-startups?pageNumber={pa}&year={year}\"\n",
    "        resp = requests.post(url, verify=False)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    \n",
    "        # Buscar todos los elementos con la clase 'items'\n",
    "        for item in soup.find_all(\"div\", class_=\"items\"):\n",
    "            # Extraer la URL desde el atributo `url` en la etiqueta <a>\n",
    "            url_element = item.find(\"a\", attrs={\"url\": True})\n",
    "            url = url_element[\"url\"] if url_element else None\n",
    "\n",
    "            # Extraer información\n",
    "            startup_name = item.find(\"h4\").text.strip() if item.find(\"h4\") else None\n",
    "            company_name = item.find(\"div\", class_=\"item-text\").find_all(\"p\")[0].text.strip()\n",
    "            category = item.find(\"div\", class_=\"item-text\").find_all(\"p\")[1].text.strip()\n",
    "            investment_amount = item.find(\"div\", class_=\"col-md-4\").find(\"p\").text.strip()\n",
    "        \n",
    "            investors_text = item.find(\"div\", class_=\"col-md-4\").find(\"strong\")\n",
    "            investors = investors_text.find_next_sibling(string=True).strip() if investors_text else None\n",
    "        \n",
    "            date = item.find(\"p\", class_=\"date\").text.strip() if item.find(\"p\", class_=\"date\") else None\n",
    "\n",
    "            # Agregar datos a la lista\n",
    "            data.append([startup_name, company_name, category, investment_amount, investors, date, url])\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Startup\", \"Company\", \"Category\", \"Investment\", \"Investors\", \"Date\", \"URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracción de info de cada empresa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    url = \"https://startupshub.catalonia.com/\" + df.loc[i, \"URL\"]\n",
    "    print(f\"Processant [{i}]: {url}\")\n",
    "\n",
    "    try:\n",
    "        # Inicialitzar driver i accedir a la pàgina\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # petita pausa per permetre càrrega\n",
    "\n",
    "        # Petició per fer servir BeautifulSoup\n",
    "        resp = requests.get(url, verify=False)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "        # Comprovació de l'adreça\n",
    "        address_element = soup.find('strong', class_='company-name')\n",
    "        if not address_element or not address_element.find_next_sibling(string=True):\n",
    "            print(f\"No hi ha adreça. Es salta.\")\n",
    "            continue\n",
    "        address = address_element.find_next_sibling(string=True).strip()\n",
    "\n",
    "        # Dades estàtiques via BeautifulSoup\n",
    "        name = soup.find('h1', class_='big_title').text.strip() if soup.find('h1', class_='big_title') else None\n",
    "        description = soup.find('meta', {'name': 'description'})['content'] if soup.find('meta', {'name': 'description'}) else None\n",
    "        founded = soup.find('span', class_='founded').find('strong').text.strip() if soup.find('span', class_='founded') else None\n",
    "        employees = soup.find('span', class_='employers').find('strong').text.strip() if soup.find('span', class_='employers') else None\n",
    "\n",
    "        # Camps opcionals amb control\n",
    "        def safe_text(selector, label=''):\n",
    "            element = soup.find('span', class_=selector)\n",
    "            return element.text.replace(label, '').strip() if element else None\n",
    "\n",
    "        industries = safe_text('industries information-item', 'Industries:')\n",
    "        technologies = safe_text('technologies information-item', 'Technologies:')\n",
    "        others_fields = safe_text('otherFields information-item', 'Other fields:')\n",
    "        financial_founded = safe_text('founded information-item', 'Founded:')\n",
    "        business_model = safe_text('model information-item', 'Business model:')\n",
    "        targets = safe_text('target information-item', 'Target:')\n",
    "        spinoff = safe_text('spinoffs information-item', 'Spinoff participants:')\n",
    "\n",
    "        # Rondas de finançament\n",
    "        funding_info = []\n",
    "        for funding in soup.find_all('div', class_='item punts-servei-content row-fluid'):\n",
    "            amount = funding.find('h3').text.strip()\n",
    "            date = amount.split('(')[-1].replace(')', '')\n",
    "            funding_info.append({'amount': amount, 'date': date})\n",
    "\n",
    "        # Elements dinàmics amb Selenium + WebDriverWait\n",
    "        try:\n",
    "            financial_funding_stage = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"fundingStageTxt\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            print(\"No s'ha trobat fundingStageTxt\")\n",
    "            financial_funding_stage = None\n",
    "\n",
    "        try:\n",
    "            financial_employees = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"employeesTxt\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            print(\"No s'ha trobat employeesTxt\")\n",
    "            financial_employees = None\n",
    "\n",
    "        try:\n",
    "            founding = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CLASS_NAME, \"generic-container\"))\n",
    "            )[0].text\n",
    "        except TimeoutException:\n",
    "            print(\"No s'ha trobat generic-container\")\n",
    "            founding = None\n",
    "\n",
    "        # Guardar dades\n",
    "        data = {\n",
    "            'Name': [name],\n",
    "            'Description': [description],\n",
    "            'Address': [address],\n",
    "            'Industries': [industries],\n",
    "            'Technologies': [technologies],\n",
    "            'Other fields': [others_fields],\n",
    "            'Funding stage': [financial_funding_stage],\n",
    "            'Founded': [financial_founded],\n",
    "            'Employees': [financial_employees],\n",
    "            'Business model': [business_model],\n",
    "            'Target': [targets],\n",
    "            'Spinoff participants': [spinoff],\n",
    "            'Funding': [funding_info],\n",
    "            'Funding2': [founding]\n",
    "        }\n",
    "\n",
    "        lista.append(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperat a [{i}]: {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/lista.pkl', 'wb') as f:\n",
    "    pickle.dump(lista, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = []\n",
    "with open('data/lista.pkl', 'rb') as f:\n",
    "    lista = pickle.load(f)\n",
    "df_info = pd.DataFrame(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(lista)\n",
    "df_info[\"Name\"] = [d[0] for d in df_info[\"Name\"]]\n",
    "df_info[\"Description\"] = [d[0] for d in df_info[\"Description\"]]\n",
    "df_info[\"Address\"] = [d[0] for d in df_info[\"Address\"]]\n",
    "df_info[\"Industries\"] = [d[0] for d in df_info[\"Industries\"]]\n",
    "df_info[\"Technologies\"] = [d[0] for d in df_info[\"Technologies\"]]\n",
    "df_info[\"Other fields\"] = [d[0] for d in df_info[\"Other fields\"]]\n",
    "df_info[\"Funding stage\"] = [d[0] for d in df_info[\"Funding stage\"]]\n",
    "df_info[\"Founded\"] = [d[0] for d in df_info[\"Founded\"]]\n",
    "df_info[\"Employees\"] = [d[0] for d in df_info[\"Employees\"]]\n",
    "df_info[\"Business model\"] = [d[0] for d in df_info[\"Business model\"]]\n",
    "df_info[\"Target\"] = [d[0] for d in df_info[\"Target\"]]\n",
    "df_info[\"Spinoff participants\"] = [d[0] for d in df_info[\"Spinoff participants\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosFinal = df.merge(df_info, left_on='Company', right_on='Name')\n",
    "datosFinal.to_pickle(\"datosFinal.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 21)\n"
     ]
    }
   ],
   "source": [
    "datosFinal = pd.read_pickle(\"datosFinal.pkl\")\n",
    "print(datosFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dades = datosFinal[~datosFinal.Name.duplicated(keep='first')]\n",
    "dades = dades[~dades.Funding2.duplicated(keep='first')]\n",
    "dades = dades.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n",
      "623\n"
     ]
    }
   ],
   "source": [
    "conteoRegistros = []\n",
    "capitales = []\n",
    "investors = []\n",
    "\n",
    "for j in range(dades.shape[0]):\n",
    "    lista = dades.loc[j, \"Funding2\"][0].split(\"\\n\")\n",
    "    \n",
    "    capital_vals = []\n",
    "    investor_vals = []\n",
    "    \n",
    "    i = 1  # comencem en la posició 1 (el segon element)\n",
    "    while i + 1 < len(lista):  # assegurem que hi ha com a mínim 3 elements (diners, capital, investor)\n",
    "        valor_diners = lista[i]\n",
    "        etiqueta_capital = lista[i + 1].lower().strip()\n",
    "        \n",
    "        # Si l’etiqueta és 'capital' (o similar) i no conté 'source', l’afegim\n",
    "        if (\n",
    "            any(etiqueta_capital.startswith(variant) for variant in ['capital', 'cpaital', 'minority stake']) and\n",
    "            'source' not in etiqueta_capital\n",
    "        ):\n",
    "            capital_vals.append(valor_diners)\n",
    "            \n",
    "            if i + 2 < len(lista):\n",
    "                investor_vals.append(lista[i + 2].replace('Investors:', '').strip())\n",
    "        \n",
    "        i += 3  # avancem al següent bloc de 3\n",
    "\n",
    "    conteoRegistros.append(len(capital_vals))\n",
    "    capitales.append(capital_vals)\n",
    "    investors.append(investor_vals)\n",
    "\n",
    "# Aplanem les llistes\n",
    "capitales = [item for sublista in capitales for item in sublista]\n",
    "investors = [item for sublista in investors for item in sublista]\n",
    "\n",
    "print(len(capitales))\n",
    "print(len(investors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repetido = dades.loc[dades.index.repeat(conteoRegistros)].reset_index(drop=True)\n",
    "df_repetido[\"capital_prev\"] = capitales\n",
    "df_repetido[\"investors\"] = investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosFinal = df_repetido.drop(columns=['Funding', 'Funding2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosFinal.to_csv('datosFinal.csv', index=False)\n",
    "datosFinal.to_pickle(\"./datosFinal.pkl\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
