{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Opcional per evitar warnings de HTTPS\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracción de empresas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for year in [2025, 2024, 2023, 2022]:\n",
    "    for pa in range(1, 8):\n",
    "        url = f\"https://startupshub.catalonia.com/investments-in-catalan-startups?pageNumber={pa}&year={year}\"\n",
    "        resp = requests.post(url, verify=False)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    \n",
    "        # Buscar todos los elementos con la clase 'items'\n",
    "        for item in soup.find_all(\"div\", class_=\"items\"):\n",
    "            # Extraer la URL desde el atributo `url` en la etiqueta <a>\n",
    "            url_element = item.find(\"a\", attrs={\"url\": True})\n",
    "            url = url_element[\"url\"] if url_element else None\n",
    "\n",
    "            # Extraer información\n",
    "            startup_name = item.find(\"h4\").text.strip() if item.find(\"h4\") else None\n",
    "            company_name = item.find(\"div\", class_=\"item-text\").find_all(\"p\")[0].text.strip()\n",
    "            category = item.find(\"div\", class_=\"item-text\").find_all(\"p\")[1].text.strip()\n",
    "            investment_amount = item.find(\"div\", class_=\"col-md-4\").find(\"p\").text.strip()\n",
    "        \n",
    "            investors_text = item.find(\"div\", class_=\"col-md-4\").find(\"strong\")\n",
    "            investors = investors_text.find_next_sibling(string=True).strip() if investors_text else None\n",
    "        \n",
    "            date = item.find(\"p\", class_=\"date\").text.strip() if item.find(\"p\", class_=\"date\") else None\n",
    "\n",
    "            # Agregar datos a la lista\n",
    "            data.append([startup_name, company_name, category, investment_amount, investors, date, url])\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Startup\", \"Company\", \"Category\", \"Investment\", \"Investors\", \"Date\", \"URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Startup                                Company  \\\n",
      "0                    TRAVELPERK                          TRAVELPERK SL   \n",
      "1    FACTORIAL RECURSOS HUMANOS                   EVERYDAY SOFTWARE SL   \n",
      "2                      SATELIOT             SATELIO IOT SERVICES, S.L.   \n",
      "3                       DEEPULL  DEEPULL DIAGNOSTICS SOCIEDAD LIMITADA   \n",
      "4                         BELVO                     BELVO TECHNOLOGIES   \n",
      "..                          ...                                    ...   \n",
      "466              QUALITY CLOUDS                   QUALITY CLOUDS, S.L.   \n",
      "467                   ZOUNDREAM                         ZOUNDREAM S.L.   \n",
      "468                        SILT                     SILT DIGITAL ID SL   \n",
      "469                      CONKAU            CONSTRUMARKET DIGITAL, S.L.   \n",
      "470                        SYRA                        SYRA COFFE S.L.   \n",
      "\n",
      "                                     Category Investment  \\\n",
      "0                        Traveltech & Leisure     190M €   \n",
      "1                Business Services & Software     110M €   \n",
      "2    ICT & MobileSustainable mobilityGov tech      70M €   \n",
      "3                                  Healthtech      50M €   \n",
      "4                                   Financing      15M €   \n",
      "..                                        ...        ...   \n",
      "466   AgricultureBusiness Services & Software              \n",
      "467    HealthtechBusiness Services & Software              \n",
      "468     Business Services & SoftwareLegaltech              \n",
      "469              Business Services & Software              \n",
      "470                                      Food              \n",
      "\n",
      "                                             Investors          Date  \\\n",
      "0                        Atomico, EQT Growth, Kinnevik  January 2025   \n",
      "1                                     General Catalyst    March 2025   \n",
      "2                                  Hyperion Fund, SETT    March 2025   \n",
      "3    Columbus Venture Partner, Panakès Partners i M...    April 2025   \n",
      "4                                Quona Capital, Kaszek    April 2025   \n",
      "..                                                 ...           ...   \n",
      "466  Adara Ventures, YFM Equity Partners, Aldea Ven...      May 2022   \n",
      "467                                               n.a.      May 2022   \n",
      "468                                  4Founders Capital    March 2022   \n",
      "469                                     Antai Ventures  January 2022   \n",
      "470                                          Crowdcube  January 2022   \n",
      "\n",
      "                                                   URL  \n",
      "0                    startup/barcelona/travelperk/1195  \n",
      "1    startup/barcelona/factorial-recursos-humanos/4087  \n",
      "2                      startup/barcelona/sateliot/4620  \n",
      "3                       startup/barcelona/deepull/6027  \n",
      "4                         startup/barcelona/belvo/4622  \n",
      "..                                                 ...  \n",
      "466              startup/barcelona/quality-clouds/6489  \n",
      "467                   startup/barcelona/zoundream/5965  \n",
      "468                        startup/barcelona/silt/5339  \n",
      "469                      startup/barcelona/conkau/6045  \n",
      "470                        startup/barcelona/syra/6044  \n",
      "\n",
      "[471 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracción de info de cada empresa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    url = \"https://startupshub.catalonia.com/\" + df.loc[i, \"URL\"]\n",
    "    print(f\"Processant [{i}]: {url}\")\n",
    "\n",
    "    try:\n",
    "        # Inicialitzar driver i accedir a la pàgina\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # petita pausa per permetre càrrega\n",
    "\n",
    "        # Petició per fer servir BeautifulSoup\n",
    "        resp = requests.get(url, verify=False)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "        # Comprovació de l'adreça\n",
    "        address_element = soup.find('strong', class_='company-name')\n",
    "        if not address_element or not address_element.find_next_sibling(string=True):\n",
    "            print(f\"No hi ha adreça. Es salta.\")\n",
    "            continue\n",
    "        address = address_element.find_next_sibling(string=True).strip()\n",
    "\n",
    "        # Dades estàtiques via BeautifulSoup\n",
    "        name = soup.find('h1', class_='big_title').text.strip() if soup.find('h1', class_='big_title') else None\n",
    "        description = soup.find('meta', {'name': 'description'})['content'] if soup.find('meta', {'name': 'description'}) else None\n",
    "        founded = soup.find('span', class_='founded').find('strong').text.strip() if soup.find('span', class_='founded') else None\n",
    "        employees = soup.find('span', class_='employers').find('strong').text.strip() if soup.find('span', class_='employers') else None\n",
    "\n",
    "        # Camps opcionals amb control\n",
    "        def safe_text(selector, label=''):\n",
    "            element = soup.find('span', class_=selector)\n",
    "            return element.text.replace(label, '').strip() if element else None\n",
    "\n",
    "        industries = safe_text('industries information-item', 'Industries:')\n",
    "        technologies = safe_text('technologies information-item', 'Technologies:')\n",
    "        others_fields = safe_text('otherFields information-item', 'Other fields:')\n",
    "        financial_founded = safe_text('founded information-item', 'Founded:')\n",
    "        business_model = safe_text('model information-item', 'Business model:')\n",
    "        targets = safe_text('target information-item', 'Target:')\n",
    "        spinoff = safe_text('spinoffs information-item', 'Spinoff participants:')\n",
    "\n",
    "        # Rondas de finançament\n",
    "        funding_info = []\n",
    "        for funding in soup.find_all('div', class_='item punts-servei-content row-fluid'):\n",
    "            amount = funding.find('h3').text.strip()\n",
    "            date = amount.split('(')[-1].replace(')', '')\n",
    "            funding_info.append({'amount': amount, 'date': date})\n",
    "\n",
    "        # Elements dinàmics amb Selenium + WebDriverWait\n",
    "        try:\n",
    "            financial_funding_stage = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"fundingStageTxt\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            print(\"No s'ha trobat fundingStageTxt\")\n",
    "            financial_funding_stage = None\n",
    "\n",
    "        try:\n",
    "            financial_employees = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"employeesTxt\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            print(\"No s'ha trobat employeesTxt\")\n",
    "            financial_employees = None\n",
    "\n",
    "        try:\n",
    "            founding = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CLASS_NAME, \"generic-container\"))\n",
    "            )[0].text\n",
    "        except TimeoutException:\n",
    "            print(\"No s'ha trobat generic-container\")\n",
    "            founding = None\n",
    "\n",
    "        # Guardar dades\n",
    "        data = {\n",
    "            'Name': [name],\n",
    "            'Description': [description],\n",
    "            'Address': [address],\n",
    "            'Industries': [industries],\n",
    "            'Technologies': [technologies],\n",
    "            'Other fields': [others_fields],\n",
    "            'Funding stage': [financial_funding_stage],\n",
    "            'Founded': [financial_founded],\n",
    "            'Employees': [financial_employees],\n",
    "            'Business model': [business_model],\n",
    "            'Target': [targets],\n",
    "            'Spinoff participants': [spinoff],\n",
    "            'Funding': [funding_info],\n",
    "            'Funding2': [founding]\n",
    "        }\n",
    "\n",
    "        lista.append(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperat a [{i}]: {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/lista.pkl', 'wb') as f:\n",
    "    pickle.dump(lista, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = []\n",
    "with open('data/lista.pkl', 'rb') as f:\n",
    "    lista = pickle.load(f)\n",
    "df_info = pd.DataFrame(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_info.columns)\n",
    "print(df_info[\"Funding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(lista)\n",
    "df_info[\"Name\"] = [d[0] for d in df_info[\"Name\"]]\n",
    "df_info[\"Description\"] = [d[0] for d in df_info[\"Description\"]]\n",
    "df_info[\"Address\"] = [d[0] for d in df_info[\"Address\"]]\n",
    "df_info[\"Industries\"] = [d[0] for d in df_info[\"Industries\"]]\n",
    "df_info[\"Technologies\"] = [d[0] for d in df_info[\"Technologies\"]]\n",
    "df_info[\"Other fields\"] = [d[0] for d in df_info[\"Other fields\"]]\n",
    "df_info[\"Funding stage\"] = [d[0] for d in df_info[\"Funding stage\"]]\n",
    "df_info[\"Founded\"] = [d[0] for d in df_info[\"Founded\"]]\n",
    "df_info[\"Employees\"] = [d[0] for d in df_info[\"Employees\"]]\n",
    "df_info[\"Business model\"] = [d[0] for d in df_info[\"Business model\"]]\n",
    "df_info[\"Target\"] = [d[0] for d in df_info[\"Target\"]]\n",
    "df_info[\"Spinoff participants\"] = [d[0] for d in df_info[\"Spinoff participants\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosFinal = df.merge(df_info, left_on='Company', right_on='Name')\n",
    "datosFinal.to_pickle(\"datosFinal.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosFinal = pd.read_pickle(\"datosFinal.pkl\")\n",
    "print(datosFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(datosFinal.head(3))\n",
    "print(datosFinal[datosFinal[\"Startup\"].str.strip().str.upper() == \"TRAVELPERK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datosFinal.loc[2, \"Funding2\"][0].split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteoRegistros = []\n",
    "capitales = []\n",
    "investors = []\n",
    "\n",
    "for j in range(datosFinal.shape[0]):\n",
    "    lista = datosFinal.loc[j, \"Funding2\"][0].split(\"\\n\")\n",
    "    capital_prev_values = [lista[i - 1] for i, val in enumerate(lista) if val.lower() == 'capital' and i > 0]\n",
    "    investors_cleaned = [val.replace('Investors:', '').strip() for val in lista if 'Investors' in val]\n",
    "    conteoRegistros.append(len(capital_prev_values))\n",
    "    capitales.append(capital_prev_values)\n",
    "    investors.append(investors_cleaned)\n",
    "\n",
    "capitales = [item for sublista in capitales for item in sublista]\n",
    "investors = [item for sublista in investors for item in sublista]\n",
    "\n",
    "print(capitales)\n",
    "print(investors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repetido = datosFinal.loc[datosFinal.index.repeat(conteoRegistros)].reset_index(drop=True)\n",
    "df_repetido[\"capital_prev\"] = capitales\n",
    "df_repetido[\"investors\"] = investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repetido = datosFinal.loc[datosFinal.index.repeat(conteoRegistros)].reset_index(drop=True)\n",
    "print(df_repetido.iloc[0:0])\n",
    "print(\"df_repetido:\", len(df_repetido))\n",
    "print(\"capitales:\", len(capitales))\n",
    "print(\"investors:\", len(investors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosFinal = df_repetido.drop(columns=['Funding', 'Funding2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosFinal.to_csv('datosFinal.csv', index=False)\n",
    "datosFinal.to_pickle(\"./datosFinal.pkl\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
