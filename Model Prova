!pip install datasets

from transformers import BertTokenizer, BertModel, Trainer, TrainingArguments
from torch import nn
import torch
from datasets import Dataset
import pandas as pd


# 1 Carregar dades (simulem un dataset amb text i finançament com a target)

data = {"text": [
    "Startup d'IA per al sector mèdic amb algoritmes avançats.",
    "Empresa fintech que utilitza blockchain per a transaccions segures.",
    "Plataforma d'e-commerce per a petits negocis amb recomanacions personalitzades."
], "funding": [5000000, 12000000, 3000000]}

df = pd.DataFrame(data)
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

# Convertir a dataset
dataset = Dataset.from_pandas(df)
print(dataset)
 # Retorna una llista amb els valors


# 2 Carregar el tokenizer de BERT

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
print(tokenizer)

tokenized_dataset = dataset.map(tokenize_function, batched=True)
tokenized_dataset.set_format("torch")


# 3 Definir el model amb una capa de regressió

class BertForFundingPrediction(nn.Module):
    def __init__(self):
        super(BertForFundingPrediction, self).__init__()
        self.bert = BertModel.from_pretrained("bert-base-uncased")
        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)  # Capa final per a regressió

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output  # Vector representatiu del text
        return self.regressor(pooled_output)  # Retorna la predicció

model = BertForFundingPrediction()


# 4 Definir els arguments d'entrenament

training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
)


# 5 Definir la funció de pèrdua per a regressió

def compute_loss(pred, labels):
    return nn.MSELoss()(pred.view(-1), labels.view(-1))


# 6 Crear l'entrenador

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    compute_metrics=compute_loss,
)


# 7 Entrenar el model

trainer.train()
